{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "population_df = pd.read_csv(\"input_data/population_by_country_AUG.2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell performs initial data cleaning:\n",
    "1. Checks for missing values in the dataset.\n",
    "2. Removes rows with missing values.\n",
    "3. Checks for and removes duplicate entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in population_df dataset:\n",
      "Geography     0\n",
      "Population    0\n",
      "dtype: int64\n",
      "\n",
      "Duplicates in population_df dataset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in population_df dataset:\")\n",
    "print(population_df.isnull().sum())\n",
    "\n",
    "# Remove rows with missing values\n",
    "population_df = population_df.dropna()\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nDuplicates in population_df dataset:\")\n",
    "print(population_df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "population_df = population_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Regions and Assigning to Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section identifies regions and assigns them to countries:\n",
    "1. Identifies rows that represent regions (entries in all caps in the 'Geography' column).\n",
    "2. Creates a new 'region' column in the dataset.\n",
    "3. Iterates through the dataset, assigning the appropriate region to each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows that represent regions (ALL CAPS entries in 'Geography')\n",
    "regions = population_df[population_df['Geography'].str.isupper()].copy()\n",
    "\n",
    "# Create an empty column for regions in the population_df\n",
    "population_df['region'] = None\n",
    "\n",
    "# Iterate over the regions and assign the corresponding region to countries\n",
    "current_region = None\n",
    "for index, row in population_df.iterrows():\n",
    "    if row['Geography'].isupper():\n",
    "        # If the row is a region, set it as the current region\n",
    "        current_region = row['Geography']\n",
    "    else:\n",
    "        # If the row is a country, assign the current region\n",
    "        population_df.at[index, 'region'] = current_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Final Country Population Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates the final country population dataset:\n",
    "1. Removes rows corresponding to regions, keeping only country data.\n",
    "2. Renames the 'Geography' column to 'country' for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows corresponding to regions and keep only the country rows\n",
    "country_population_df = population_df[~population_df['Geography'].str.isupper()].copy()\n",
    "\n",
    "# Rename the columns to 'country'\n",
    "country_population_df = country_population_df.rename(columns={'Geography': 'country'})\n",
    "\n",
    "# Save the final DataFrame to a CSV file for future use\n",
    "country_population_df.to_csv('intermediate_data/population_by_country_with_region.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Politicians Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import unquote\n",
    "\n",
    "politicians_df = pd.read_csv(\"input_data/politicians_by_country_AUG.2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell performs initial data cleaning:\n",
    "1. Checks for missing values in the dataset.\n",
    "2. Removes rows with missing values.\n",
    "3. Checks for and removes duplicate entries in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in population_df dataset:\n",
      "Geography      0\n",
      "Population     0\n",
      "region        24\n",
      "dtype: int64\n",
      "\n",
      "Duplicates in population_df dataset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in population_df dataset:\")\n",
    "print(population_df.isnull().sum())\n",
    "\n",
    "# Remove rows with missing values\n",
    "population_df = population_df.dropna()\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nDuplicates in population_df dataset:\")\n",
    "print(population_df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "population_df = population_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predicted Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ORES_API_ENDPOINT = \"https://ores.wikimedia.org/v3/scores/enwiki/{revid}/articlequality\"\n",
    "MEDIAWIKI_API_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "INPUT_FILE = 'input_data/politicians_by_country_AUG.2024.csv'\n",
    "OUTPUT_FILE = 'intermediate_data/politicians_with_quality_and_revisions.csv'\n",
    "ERROR_LOG_FILE = 'intermediate_data/error_log.txt'\n",
    "\n",
    "REQUEST_HEADER = {\n",
    "    'User-Agent': \"<pgupta1@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2024\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions handle various tasks:\n",
    "1. Extracting article titles from URLs.\n",
    "2. Getting the current revision ID for a given article.\n",
    "3. Requesting ORES quality scores for article revisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_title_from_url(url):\n",
    "    \"\"\"Extract the article title from a Wikipedia URL.\"\"\"\n",
    "    parts = url.split(\"/\")\n",
    "    if len(parts) > 4:\n",
    "        return unquote(parts[4].replace(\"_\", \" \"))\n",
    "    return url\n",
    "\n",
    "def get_current_revision(title):\n",
    "    \"\"\"Get the current revision ID for a given Wikipedia article title.\"\"\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"revisions\",\n",
    "        \"rvprop\": \"ids\",\n",
    "        \"rvlimit\": 1\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(MEDIAWIKI_API_ENDPOINT, params=params, headers=REQUEST_HEADER)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        page = next(iter(data['query']['pages'].values()))\n",
    "        return page['revisions'][0]['revid']\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def request_ores_score(rev_id):\n",
    "    \"\"\"Get ORES quality prediction for a given article revision.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(ORES_API_ENDPOINT.format(revid=rev_id), headers=REQUEST_HEADER)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data['enwiki']['scores'][str(rev_id)]['articlequality']['score']['prediction']\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting ORES score for rev_id {rev_id}: {str(e)}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is the main workhorse of the script:\n",
    "1. It loads the input data.\n",
    "2. Processes each article to get its current revision ID and quality score.\n",
    "3. Handles errors and logs them.\n",
    "4. Saves progress periodically and outputs the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the CSV file:\n",
      "['name', 'url', 'country']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   0%|          | 0/7155 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   1%|▏         | 100/7155 [02:01<2:26:12,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   3%|▎         | 200/7155 [04:00<2:44:08,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 200 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   4%|▍         | 300/7155 [06:35<5:13:10,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 300 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   6%|▌         | 400/7155 [08:49<2:23:13,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 400 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   7%|▋         | 500/7155 [10:57<2:40:14,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 500 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:   8%|▊         | 600/7155 [13:54<2:41:57,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 600 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  10%|▉         | 700/7155 [16:11<1:54:08,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 700 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  11%|█         | 800/7155 [18:05<2:05:39,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 800 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  13%|█▎        | 900/7155 [20:07<2:05:53,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 900 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  14%|█▍        | 1000/7155 [22:01<1:55:07,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1000 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  15%|█▌        | 1100/7155 [24:07<1:54:59,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  17%|█▋        | 1200/7155 [26:05<2:11:21,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1200 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  18%|█▊        | 1300/7155 [28:00<1:43:01,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1300 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  20%|█▉        | 1400/7155 [29:51<1:57:41,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1400 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  21%|██        | 1500/7155 [31:45<1:46:14,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1500 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  22%|██▏       | 1600/7155 [33:37<1:51:56,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1600 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  23%|██▎       | 1666/7155 [35:56<29:02:59, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 504 Server Error: Gateway Timeout for url: https://ores.wikimedia.org/v3/scores/enwiki/1208171356/articlequality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  24%|██▍       | 1700/7155 [36:34<1:43:29,  1.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1700 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  25%|██▌       | 1800/7155 [38:25<1:38:44,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1800 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  27%|██▋       | 1900/7155 [40:25<1:53:30,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 1900 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  28%|██▊       | 2000/7155 [42:30<1:33:05,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2000 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  29%|██▉       | 2100/7155 [44:29<1:39:45,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  31%|███       | 2200/7155 [46:29<1:30:45,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2200 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  32%|███▏      | 2300/7155 [48:22<1:27:10,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2300 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  34%|███▎      | 2400/7155 [50:17<1:47:15,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2400 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  35%|███▍      | 2500/7155 [52:19<1:32:17,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2500 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  36%|███▋      | 2600/7155 [54:17<1:26:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2600 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  38%|███▊      | 2700/7155 [56:21<1:20:58,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2700 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  39%|███▉      | 2800/7155 [58:22<1:20:48,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2800 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  41%|████      | 2900/7155 [1:00:17<1:20:28,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 2900 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  42%|████▏     | 3000/7155 [1:02:12<1:15:26,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3000 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  43%|████▎     | 3100/7155 [1:04:06<1:23:24,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  45%|████▍     | 3200/7155 [1:05:58<1:17:15,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3200 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  46%|████▌     | 3300/7155 [1:07:49<1:10:54,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3300 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  48%|████▊     | 3400/7155 [1:09:45<1:06:25,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3400 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  48%|████▊     | 3454/7155 [1:11:57<19:44:20, 19.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 504 Server Error: Gateway Timeout for url: https://ores.wikimedia.org/v3/scores/enwiki/1067021356/articlequality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  48%|████▊     | 3455/7155 [1:12:58<32:36:50, 31.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 504 Server Error: Gateway Timeout for url: https://ores.wikimedia.org/v3/scores/enwiki/1231810366/articlequality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  49%|████▉     | 3500/7155 [1:13:53<1:04:36,  1.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3500 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  50%|█████     | 3600/7155 [1:15:48<1:22:39,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3600 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  52%|█████▏    | 3700/7155 [1:17:53<1:02:14,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3700 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  53%|█████▎    | 3800/7155 [1:19:51<1:19:32,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3800 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  55%|█████▍    | 3900/7155 [1:21:48<1:02:16,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 3900 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  56%|█████▌    | 4000/7155 [1:23:51<1:06:36,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4000 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  57%|█████▋    | 4100/7155 [1:25:57<1:01:34,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  59%|█████▊    | 4200/7155 [1:27:57<54:24,  1.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4200 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  60%|██████    | 4300/7155 [1:29:56<55:27,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4300 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  61%|██████▏   | 4400/7155 [1:31:52<51:45,  1.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4400 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  63%|██████▎   | 4500/7155 [1:33:54<49:02,  1.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4500 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  64%|██████▍   | 4600/7155 [1:35:55<52:41,  1.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4600 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  66%|██████▌   | 4700/7155 [1:38:01<45:17,  1.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4700 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  66%|██████▋   | 4743/7155 [1:40:03<12:49:36, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP error occurred: 504 Server Error: Gateway Timeout for url: https://ores.wikimedia.org/v3/scores/enwiki/747227236/articlequality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  67%|██████▋   | 4800/7155 [1:41:22<47:43,  1.22s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4800 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  68%|██████▊   | 4900/7155 [1:43:27<43:23,  1.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 4900 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  70%|██████▉   | 5000/7155 [1:45:37<40:20,  1.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5000 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  71%|███████▏  | 5100/7155 [1:47:34<38:27,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  73%|███████▎  | 5200/7155 [1:49:33<41:27,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5200 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  74%|███████▍  | 5300/7155 [1:51:27<31:51,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5300 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  75%|███████▌  | 5400/7155 [1:53:24<35:29,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5400 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  77%|███████▋  | 5500/7155 [1:55:28<33:47,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5500 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  78%|███████▊  | 5600/7155 [1:57:34<27:54,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5600 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  80%|███████▉  | 5700/7155 [1:59:35<33:26,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5700 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  81%|████████  | 5800/7155 [2:01:35<25:26,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5800 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  82%|████████▏ | 5900/7155 [2:03:37<26:51,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 5900 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  84%|████████▍ | 6000/7155 [2:05:37<23:22,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6000 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  85%|████████▌ | 6100/7155 [2:07:38<21:54,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  87%|████████▋ | 6200/7155 [2:09:49<18:16,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6200 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  88%|████████▊ | 6300/7155 [2:11:48<15:50,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6300 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  89%|████████▉ | 6400/7155 [2:14:03<17:22,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6400 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  91%|█████████ | 6500/7155 [2:16:03<12:07,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6500 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  92%|█████████▏| 6600/7155 [2:18:03<13:06,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6600 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  94%|█████████▎| 6700/7155 [2:20:08<08:56,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6700 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  95%|█████████▌| 6800/7155 [2:22:05<07:20,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6800 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  96%|█████████▋| 6900/7155 [2:24:03<05:11,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 6900 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  98%|█████████▊| 7000/7155 [2:26:04<03:06,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 7000 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles:  99%|█████████▉| 7100/7155 [2:28:08<01:05,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved. Processed 7100 articles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing articles: 100%|██████████| 7155/7155 [2:29:15<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error rate: 0.17%\n",
      "\n",
      "Final results saved to politicians_with_quality_and_revisions.csv\n",
      "Error log saved to error_log.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_politicians_data():\n",
    "    \"\"\"Process all the politicians data and get quality predictions.\"\"\"\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "    \n",
    "    print(\"Columns in the CSV file:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    url_column = 'url' \n",
    "    \n",
    "    if url_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{url_column}' not found in the CSV file.\")\n",
    "    \n",
    "    df['quality'] = None\n",
    "    df['revision_id'] = None\n",
    "    error_count = 0\n",
    "    error_log = []\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing articles\"):\n",
    "        url = row[url_column]\n",
    "        title = extract_title_from_url(url)\n",
    "        rev_id = get_current_revision(title)\n",
    "        \n",
    "        if rev_id:\n",
    "            df.at[index, 'revision_id'] = rev_id\n",
    "            quality = request_ores_score(rev_id)\n",
    "            if quality:\n",
    "                df.at[index, 'quality'] = quality\n",
    "            else:\n",
    "                error_count += 1\n",
    "                error_msg = f\"Failed to get ORES score for {title} (rev_id: {rev_id})\"\n",
    "                error_log.append(error_msg)\n",
    "        else:\n",
    "            error_count += 1\n",
    "            error_msg = f\"Failed to get revision ID for {title}\"\n",
    "            error_log.append(error_msg)\n",
    "        \n",
    "        # Save progress every 100 articles\n",
    "        if (index + 1) % 100 == 0:\n",
    "            df.to_csv(OUTPUT_FILE, index=False)\n",
    "            print(f\"Progress saved. Processed {index+1} articles.\")\n",
    "\n",
    "    # Calculate and print error rate\n",
    "    total_articles = len(df)\n",
    "    error_rate = error_count / total_articles\n",
    "    print(f\"\\nError rate: {error_rate:.2%}\")\n",
    "\n",
    "    if error_rate > 0.01:\n",
    "        print(\"Error rate is above 1%. Please review the error log.\")\n",
    "    \n",
    "    # Log errors\n",
    "    with open(ERROR_LOG_FILE, 'w') as f:\n",
    "        for error in error_log:\n",
    "            f.write(f\"{error}\\n\")\n",
    "\n",
    "    # Save final results\n",
    "    df.to_csv(OUTPUT_FILE, index=False)\n",
    "    print(f\"\\nFinal results saved to {OUTPUT_FILE}\")\n",
    "    print(f\"Error log saved to {ERROR_LOG_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_politicians_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
